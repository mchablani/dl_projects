{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use content loss to create a super-resolution network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.insert(0, '../util')\n",
    "import utils; importlib.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '/mnt/data/manish/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_lr = bcolz.open(dpath+'trn_resized_72.bc')[:]\n",
    "arr_hr = bcolz.open(dpath+'trn_resized_288.bc')[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parms = {'verbose': 1, 'callbacks': [TQDMNotebookCallback(leave_inner=True)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, size, stride=(2,2), mode='same', act=True):\n",
    "    x = Convolution2D(filters, size, size, subsample=stride, border_mode=mode)(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x) if act else x\n",
    "\n",
    "def res_block(ip, nf=64):\n",
    "    x = conv_block(ip, nf, 3, (1,1))\n",
    "    x = conv_block(x, nf, 3, (1,1), act=False)\n",
    "    return merge([x, ip], mode='sum')\n",
    "\n",
    "def deconv_block(x, filters, size, shape, stride=(2,2)):\n",
    "    x = Deconvolution2D(filters, size, size, subsample=stride, \n",
    "        border_mode='same', output_shape=(None,)+shape)(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def up_block(x, filters, size):\n",
    "    x = keras.layers.UpSampling2D()(x)\n",
    "    x = Convolution2D(filters, size, size, border_mode='same')(x)\n",
    "    x = BatchNormalization(mode=2)(x)\n",
    "    return Activation('relu')(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model here is using the previously defined blocks to encode a low resolution image and \n",
    "# then upsample it to match the same image in high resolution.\n",
    "\n",
    "inp=Input(arr_lr.shape[1:])\n",
    "x=conv_block(inp, 64, 9, (1,1))\n",
    "for i in range(4): x=res_block(x)\n",
    "x=up_block(x, 64, 3)\n",
    "x=up_block(x, 64, 3)\n",
    "x=Convolution2D(3, 9, 9, activation='tanh', border_mode='same')(x)\n",
    "outp=Lambda(lambda x: (x+1)*127.5)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shp = \n",
    "shp = outp.shape[1:]\n",
    "\n",
    "preproc = lambda x: (x-imagenet_mean)[:,:,:,::-1]\n",
    "deproc = lambda x,s: np.clip(x.reshape(s)[:, :, :, ::-1] + imagenet_mean, 0, 255)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method of training this network is almost exactly the same as training the pixels from our previous implementations. The idea here is we're going to feed two images to Vgg16 and compare their convolutional outputs at some layer. These two images are the target image (which in our case is the same as the original but at higher resolution), and the output of the previous network we just defined, which we hope will learn to output a high resolution image. \n",
    "\n",
    "The key then is to train this other network to produce an image that minimizes the loss between the outputs of some convolutional layer in Vgg16 (which the paper refers to as \"perceptual loss\"). In doing so, we are able to train a network that can upsample an image and recreate the higher resolution details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_inp=Input(shp)\n",
    "vgg = VGG16(include_top=False, input_tensor=Lambda(preproc)(vgg_inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we only want to learn the \"upsampling network\", and are just using VGG to calculate the loss function, \n",
    "# we set the Vgg layers to not be trainable.\n",
    "for l in vgg.layers: l.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_4 (InputLayer)             (None, Dimension(288) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)                (None, 288, 288, 3)   0           input_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 288, 288, 64)  1792        lambda_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 288, 288, 64)  36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 144, 144, 64)  0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 144, 144, 128) 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 144, 144, 128) 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 72, 72, 128)   0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 72, 72, 256)   295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 72, 72, 256)   590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 72, 72, 256)   590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 36, 36, 256)   0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 36, 36, 512)   1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 36, 36, 512)   2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 36, 36, 512)   2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 18, 18, 512)   0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 18, 18, 512)   2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 18, 18, 512)   2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 18, 18, 512)   2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 9, 9, 512)     0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outp(m, o): return m.get_layer('block{}_conv1'.format(o)).output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important difference in training for super resolution is the loss function. We use what's known as a perceptual loss function (which is simply the content loss for some layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_content = Model(vgg_inp, [get_outp(vgg, o) for o in range(1,4)])\n",
    "\n",
    "vgg1 = vgg_content(vgg_inp)\n",
    "vgg2 = vgg_content(outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_sqr_b(diff): \n",
    "    dims = list(range(1,K.ndim(diff)))\n",
    "    return K.expand_dims(K.sqrt(K.mean(diff**2, dims)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=[0.1, 0.8, 0.1]\n",
    "def content_fn(x): \n",
    "    res = 0; n=len(w)\n",
    "    for i in range(n): res += mean_sqr_b(x[i]-x[i+n]) * w[i]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_sr = Model([inp, vgg_inp], Lambda(content_fn)(vgg1+vgg2))\n",
    "targ = np.zeros((arr_hr.shape[0], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we compile this chain of models and we can pass it the original low resolution image as well as the high resolution to train on. We also define a zero vector as a target parameter, which is a necessary parameter when calling fit on a keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 72, 72, 3)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_13 (Convolution2D) (None, 72, 72, 64)    15616       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_12 (BatchNorm (None, 72, 72, 64)    256         convolution2d_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_8 (Activation)        (None, 72, 72, 64)    0           batchnormalization_12[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_14 (Convolution2D) (None, 72, 72, 64)    36928       activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_13 (BatchNorm (None, 72, 72, 64)    256         convolution2d_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_9 (Activation)        (None, 72, 72, 64)    0           batchnormalization_13[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_15 (Convolution2D) (None, 72, 72, 64)    36928       activation_9[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_14 (BatchNorm (None, 72, 72, 64)    256         convolution2d_15[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_5 (Merge)                  (None, 72, 72, 64)    0           batchnormalization_14[0][0]      \n",
      "                                                                   activation_8[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_16 (Convolution2D) (None, 72, 72, 64)    36928       merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_15 (BatchNorm (None, 72, 72, 64)    256         convolution2d_16[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_10 (Activation)       (None, 72, 72, 64)    0           batchnormalization_15[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_17 (Convolution2D) (None, 72, 72, 64)    36928       activation_10[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_16 (BatchNorm (None, 72, 72, 64)    256         convolution2d_17[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_6 (Merge)                  (None, 72, 72, 64)    0           batchnormalization_16[0][0]      \n",
      "                                                                   merge_5[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_18 (Convolution2D) (None, 72, 72, 64)    36928       merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_17 (BatchNorm (None, 72, 72, 64)    256         convolution2d_18[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_11 (Activation)       (None, 72, 72, 64)    0           batchnormalization_17[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_19 (Convolution2D) (None, 72, 72, 64)    36928       activation_11[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_18 (BatchNorm (None, 72, 72, 64)    256         convolution2d_19[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_7 (Merge)                  (None, 72, 72, 64)    0           batchnormalization_18[0][0]      \n",
      "                                                                   merge_6[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_20 (Convolution2D) (None, 72, 72, 64)    36928       merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_19 (BatchNorm (None, 72, 72, 64)    256         convolution2d_20[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_12 (Activation)       (None, 72, 72, 64)    0           batchnormalization_19[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_21 (Convolution2D) (None, 72, 72, 64)    36928       activation_12[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_20 (BatchNorm (None, 72, 72, 64)    256         convolution2d_21[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "merge_8 (Merge)                  (None, 72, 72, 64)    0           batchnormalization_20[0][0]      \n",
      "                                                                   merge_7[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_3 (UpSampling2D)    (None, 144, 144, 64)  0           merge_8[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_22 (Convolution2D) (None, 144, 144, 64)  36928       upsampling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_21 (BatchNorm (None, 144, 144, 64)  256         convolution2d_22[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_13 (Activation)       (None, 144, 144, 64)  0           batchnormalization_21[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "upsampling2d_4 (UpSampling2D)    (None, 288, 288, 64)  0           activation_13[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_23 (Convolution2D) (None, 288, 288, 64)  36928       upsampling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_22 (BatchNorm (None, 288, 288, 64)  256         convolution2d_23[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "activation_14 (Activation)       (None, 288, 288, 64)  0           batchnormalization_22[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_24 (Convolution2D) (None, 288, 288, 3)   15555       activation_14[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "input_4 (InputLayer)             (None, Dimension(288) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)                (None, 288, 288, 3)   0           convolution2d_24[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  [(None, 288, 288, 64) 555328      input_4[0][0]                    \n",
      "                                                                   lambda_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)                (1, None)             0           model_1[1][0]                    \n",
      "                                                                   model_1[1][1]                    \n",
      "                                                                   model_1[1][2]                    \n",
      "                                                                   model_1[2][0]                    \n",
      "                                                                   model_1[2][1]                    \n",
      "                                                                   model_1[2][2]                    \n",
      "====================================================================================================\n",
      "Total params: 958,595\n",
      "Trainable params: 401,859\n",
      "Non-trainable params: 556,736\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m_sr.compile('adam', 'mse')\n",
    "m_sr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d665e8da6eba4783a015d5139be77580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655ed1d9966c4e228586285bbeb7fdff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "   64/19439 [..............................] - ETA: 1358s - loss: 101723.8037\n",
      "19439/19439 [==============================] - 856s - loss: 22685.9402   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f82a004beb8>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_sr.fit([arr_lr, arr_hr], targ, 16, 2, **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.get_value(m_sr.optimizer.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use learning rate annealing to get a better fit.\n",
    "print(m_sr.optimizer.lr)\n",
    "K.set_value(m_sr.optimizer.lr, 1e-4)\n",
    "m_sr.fit([arr_lr, arr_hr], targ, 16, 1, **parms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are only interested in the trained part of the model, which does the actual upsampling.\n",
    "top_model = Model(inp, outp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = top_model.predict(arr_lr[10:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(arr_lr[10].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p[0].astype('uint8'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.save_weights(dpath+'sr_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model.load_weights(dpath+'top_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The important thing to take away here is that as opposed to our earlier approaches, this type of approach results in a model that can created the desired image and is a scalable implementation.\n",
    "Note that we haven't used a test set here, so we don't know if the above result is due to over-fitting. As part of your homework, you should create a test set, and try to train a model that gets the best result you can on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
